{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created a Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Spark Lab One\") \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.8:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0-preview</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Lab One</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11289aa90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loaded employee table from MYSQL database into Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_no: integer (nullable = true)\n",
      " |-- birth_date: date (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- hire_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees = spark.read \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .option(\"url\",\"jdbc:mysql://localhost:3306/employees\")\\\n",
    "  .option(\"driver\",\"com.mysql.jdbc.Driver\")\\\n",
    "  .option(\"dbtable\",\"employees\") \\\n",
    "  .option(\"user\", \"root\") \\\n",
    "  .option(\"password\",\"mysql123\") \\\n",
    "  .load()\n",
    "\n",
    "\n",
    "\n",
    "employees.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the current age of the employees \n",
    "Function Used:\n",
    "* datediff: It will find the difference between the birth date and the current date.\n",
    "* current_date :It will return the current date.\n",
    "* floor : It will return the largest integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+---------+------+----------+---------------+\n",
      "|emp_no|birth_date|first_name|last_name|gender| hire_date|emp_current_age|\n",
      "+------+----------+----------+---------+------+----------+---------------+\n",
      "| 10001|1953-09-02|    Georgi|  Facello|     M|1986-06-26|             66|\n",
      "| 10002|1964-06-02|   Bezalel|   Simmel|     F|1985-11-21|             55|\n",
      "| 10003|1959-12-03|     Parto|  Bamford|     M|1986-08-28|             60|\n",
      "| 10004|1954-05-01| Chirstian|  Koblick|     M|1986-12-01|             65|\n",
      "| 10005|1955-01-21|   Kyoichi| Maliniak|     M|1989-09-12|             65|\n",
      "| 10006|1953-04-20|    Anneke|  Preusig|     F|1989-06-02|             66|\n",
      "| 10007|1957-05-23|   Tzvetan|Zielinski|     F|1989-02-10|             62|\n",
      "| 10008|1958-02-19|    Saniya| Kalloufi|     M|1994-09-15|             61|\n",
      "| 10009|1952-04-19|    Sumant|     Peac|     F|1985-02-18|             67|\n",
      "| 10010|1963-06-01| Duangkaew| Piveteau|     F|1989-08-24|             56|\n",
      "+------+----------+----------+---------+------+----------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate current age of the employees\n",
    "from pyspark.sql.functions import year,current_date, col, floor, month,datediff\n",
    "\n",
    "employees.withColumn(\"emp_current_age\",floor((datediff(current_date(),\"birth_date\"))/365))\\\n",
    ".show(10)\n",
    "#.select(\"emp_no\", year(\"birth_date\"),\"birth_date\", \"first_name\") \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate total number of years worked by employee\n",
    "\n",
    "Function Used:\n",
    "* year: It will return the year part of the date. \n",
    "* current_date: It will return the current date.\n",
    "* datediff:It will find the difference between the hire date and the current date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+---------+------+----------+-----------+\n",
      "|emp_no|birth_date|first_name|last_name|gender| hire_date|year worked|\n",
      "+------+----------+----------+---------+------+----------+-----------+\n",
      "| 10001|1953-09-02|    Georgi|  Facello|     M|1986-06-26|         33|\n",
      "| 10002|1964-06-02|   Bezalel|   Simmel|     F|1985-11-21|         34|\n",
      "| 10003|1959-12-03|     Parto|  Bamford|     M|1986-08-28|         33|\n",
      "| 10004|1954-05-01| Chirstian|  Koblick|     M|1986-12-01|         33|\n",
      "| 10005|1955-01-21|   Kyoichi| Maliniak|     M|1989-09-12|         30|\n",
      "| 10006|1953-04-20|    Anneke|  Preusig|     F|1989-06-02|         30|\n",
      "| 10007|1957-05-23|   Tzvetan|Zielinski|     F|1989-02-10|         30|\n",
      "| 10008|1958-02-19|    Saniya| Kalloufi|     M|1994-09-15|         25|\n",
      "| 10009|1952-04-19|    Sumant|     Peac|     F|1985-02-18|         34|\n",
      "| 10010|1963-06-01| Duangkaew| Piveteau|     F|1989-08-24|         30|\n",
      "+------+----------+----------+---------+------+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year,datediff,current_date\n",
    "\n",
    "employees.withColumn(\"year worked\",floor((datediff(current_date(),\"hire_date\"))/365)).show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the age of the employee when they are hired at the company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+---------+------+----------+--------------------+\n",
      "|emp_no|birth_date|first_name|last_name|gender| hire_date|Age of the employee |\n",
      "+------+----------+----------+---------+------+----------+--------------------+\n",
      "| 10001|1953-09-02|    Georgi|  Facello|     M|1986-06-26|                  32|\n",
      "| 10002|1964-06-02|   Bezalel|   Simmel|     F|1985-11-21|                  21|\n",
      "| 10003|1959-12-03|     Parto|  Bamford|     M|1986-08-28|                  26|\n",
      "| 10004|1954-05-01| Chirstian|  Koblick|     M|1986-12-01|                  32|\n",
      "| 10005|1955-01-21|   Kyoichi| Maliniak|     M|1989-09-12|                  34|\n",
      "| 10006|1953-04-20|    Anneke|  Preusig|     F|1989-06-02|                  36|\n",
      "| 10007|1957-05-23|   Tzvetan|Zielinski|     F|1989-02-10|                  31|\n",
      "| 10008|1958-02-19|    Saniya| Kalloufi|     M|1994-09-15|                  36|\n",
      "| 10009|1952-04-19|    Sumant|     Peac|     F|1985-02-18|                  32|\n",
      "| 10010|1963-06-01| Duangkaew| Piveteau|     F|1989-08-24|                  26|\n",
      "+------+----------+----------+---------+------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import current_date,datediff\n",
    "employees.withColumn(\"Age of the employee \",floor((datediff(\"hire_date\",'birth_date'))/365)).show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show employee birth year\n",
    "* Here we are showing just the employee birth year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|birth_year|\n",
      "+----------+\n",
      "|      1953|\n",
      "|      1964|\n",
      "|      1959|\n",
      "|      1954|\n",
      "|      1955|\n",
      "|      1953|\n",
      "|      1957|\n",
      "|      1958|\n",
      "|      1952|\n",
      "|      1963|\n",
      "|      1953|\n",
      "|      1960|\n",
      "|      1963|\n",
      "|      1956|\n",
      "|      1959|\n",
      "|      1961|\n",
      "|      1958|\n",
      "|      1954|\n",
      "|      1953|\n",
      "|      1952|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import year\n",
    "employees.select(year(\"birth_date\").alias('birth_year')).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here we are showing employee birth year along with the other columns by selecting the withColumn function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+---------+------+----------+----------+\n",
      "|emp_no|birth_date|first_name|last_name|gender| hire_date|birth_year|\n",
      "+------+----------+----------+---------+------+----------+----------+\n",
      "| 10001|1953-09-02|    Georgi|  Facello|     M|1986-06-26|      1953|\n",
      "| 10002|1964-06-02|   Bezalel|   Simmel|     F|1985-11-21|      1964|\n",
      "| 10003|1959-12-03|     Parto|  Bamford|     M|1986-08-28|      1959|\n",
      "| 10004|1954-05-01| Chirstian|  Koblick|     M|1986-12-01|      1954|\n",
      "| 10005|1955-01-21|   Kyoichi| Maliniak|     M|1989-09-12|      1955|\n",
      "| 10006|1953-04-20|    Anneke|  Preusig|     F|1989-06-02|      1953|\n",
      "| 10007|1957-05-23|   Tzvetan|Zielinski|     F|1989-02-10|      1957|\n",
      "| 10008|1958-02-19|    Saniya| Kalloufi|     M|1994-09-15|      1958|\n",
      "| 10009|1952-04-19|    Sumant|     Peac|     F|1985-02-18|      1952|\n",
      "| 10010|1963-06-01| Duangkaew| Piveteau|     F|1989-08-24|      1963|\n",
      "+------+----------+----------+---------+------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "employees.withColumn(\"birth_year\",year(\"birth_date\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create employee abbreviated name that contains 2 first character from last name and all character from first in lower case.\n",
    "\n",
    "* Function Used:\n",
    "* Substring:Extract the substring from a string.\n",
    "* concat:It will add two strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------------+\n",
      "|first_name|last_name|abbreviated_name|\n",
      "+----------+---------+----------------+\n",
      "|    Georgi|  Facello|        fageorgi|\n",
      "|   Bezalel|   Simmel|       sibezalel|\n",
      "|     Parto|  Bamford|         baparto|\n",
      "| Chirstian|  Koblick|     kochirstian|\n",
      "|   Kyoichi| Maliniak|       makyoichi|\n",
      "|    Anneke|  Preusig|        pranneke|\n",
      "|   Tzvetan|Zielinski|       zitzvetan|\n",
      "|    Saniya| Kalloufi|        kasaniya|\n",
      "|    Sumant|     Peac|        pesumant|\n",
      "| Duangkaew| Piveteau|     piduangkaew|\n",
      "+----------+---------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import substring,col,expr,concat\n",
    "employees.select(\"first_name\", \"last_name\",\\\n",
    "          expr(\"lower(concat(substring(last_name, 0, 2), substring(first_name, 0, length(first_name))))as abbreviated_name\")\\\n",
    "          ).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Displaying just the abbreviated name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|abbreviated_name|\n",
      "+----------------+\n",
      "|        fageorgi|\n",
      "|       sibezalel|\n",
      "|         baparto|\n",
      "|     kochirstian|\n",
      "|       makyoichi|\n",
      "|        pranneke|\n",
      "|       zitzvetan|\n",
      "|        kasaniya|\n",
      "|        pesumant|\n",
      "|     piduangkaew|\n",
      "+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import substring,col,concat\n",
    "\n",
    "employees.selectExpr(\"lower(concat(substring(last_name, 0, 2), substring(first_name, 0, length(first_name))))as abbreviated_name\") \\\n",
    "          .show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|emp_no|\n",
      "+------+\n",
      "| 10001|\n",
      "| 10002|\n",
      "| 10003|\n",
      "| 10004|\n",
      "| 10005|\n",
      "| 10006|\n",
      "| 10007|\n",
      "| 10008|\n",
      "| 10009|\n",
      "| 10010|\n",
      "+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#emp_no\n",
    "employees.select(col(\"emp_no\")).show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse employee number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|reverse_emp_no|\n",
      "+--------------+\n",
      "|         10001|\n",
      "|         20001|\n",
      "|         30001|\n",
      "|         40001|\n",
      "|         50001|\n",
      "|         60001|\n",
      "|         70001|\n",
      "|         80001|\n",
      "|         90001|\n",
      "|         01001|\n",
      "+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Reverse employee number.\n",
    "from pyspark.sql.functions import reverse\n",
    "employees.select(reverse(\"emp_no\").alias('reverse_emp_no')).show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
